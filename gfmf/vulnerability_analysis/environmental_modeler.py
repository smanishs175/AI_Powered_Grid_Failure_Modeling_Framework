"""
Environmental threat modeling for the Grid Failure Modeling Framework.

This module analyzes environmental conditions and their impact on power grid
vulnerabilities.
"""

import os
import numpy as np
import pandas as pd
import pickle
import logging
from typing import Dict, List, Union, Optional, Any, Tuple
import matplotlib.pyplot as plt
from datetime import datetime, timedelta

# Import utility functions
from .utils.statistical_tools import (
    calculate_correlation,
    calculate_time_lagged_correlation,
    find_optimal_threshold
)
from .utils.visualization import (
    plot_environmental_threat_heatmap,
    plot_time_series_with_events
)
from .utils.validators import validate_weather_history, validate_outage_records

# Configure logging
logger = logging.getLogger(__name__)

class EnvironmentalThreatModeler:
    """
    Environmental threat modeling module.
    
    This class analyzes environmental conditions and their impact on power grid
    vulnerabilities.
    """
    
    def __init__(self, config: Dict[str, Any]):
        """
        Initialize environmental threat modeler.
        
        Args:
            config: Configuration dictionary
        """
        self.config = config
        self.logger = logging.getLogger(__name__)
        
        # Get environmental threat config
        self.threat_config = config.get('environmental_threat', {})
        
        # Threat configuration
        self.threat_types = self.threat_config.get('threat_types', [
            'high_temperature', 'low_temperature', 'high_wind', 'precipitation'
        ])
        
        self.threshold_percentiles = self.threat_config.get('threshold_percentiles', {
            'high_temperature': 95,
            'low_temperature': 5,
            'high_wind': 95,
            'precipitation': 95
        })
        
        self.calculate_cumulative = self.threat_config.get('calculate_cumulative', True)
        self.time_lag_analysis = self.threat_config.get('time_lag_analysis', True)
        self.max_lag_days = self.threat_config.get('max_lag_days', 7)
        
        # Initialize attributes
        self.weather_thresholds = {}
        self.threat_profiles = {}
        self.lagged_correlations = {}
        
        self.logger.info("EnvironmentalThreatModeler initialized")
    
    def analyze(
        self,
        weather_history: pd.DataFrame,
        outage_records: pd.DataFrame,
        save_path: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Analyze environmental threats based on weather and outage data.
        
        Args:
            weather_history: DataFrame with weather data
            outage_records: DataFrame with outage records
            save_path: Path to save results
            
        Returns:
            Dict: Dictionary with environmental threat profiles
        """
        self.logger.info("Starting environmental threat analysis")
        
        # Validate input data
        self._validate_input_data(weather_history, outage_records)
        
        # Identify threat thresholds
        self.weather_thresholds = self._identify_threat_thresholds(
            weather_history, 
            outage_records
        )
        
        # Calculate threat profiles
        self.threat_profiles = self._calculate_threat_profiles(
            weather_history
        )
        
        # Analyze lagged correlations if configured
        if self.time_lag_analysis:
            self.lagged_correlations = self._analyze_lagged_correlations(
                weather_history,
                outage_records
            )
        
        # Generate visualizations
        self._generate_visualizations(weather_history, outage_records, save_path)
        
        # Save results if path provided
        if save_path:
            os.makedirs(save_path, exist_ok=True)
            self._save_results(save_path)
        
        self.logger.info("Completed environmental threat analysis")
        
        return self.threat_profiles
    
    def _validate_input_data(
        self,
        weather_history: pd.DataFrame,
        outage_records: pd.DataFrame
    ):
        """
        Validate input data for environmental threat modeling.
        
        Args:
            weather_history: DataFrame with weather data
            outage_records: DataFrame with outage records
        """
        # Validate weather data
        is_valid_weather, weather_issues = validate_weather_history(weather_history)
        if not is_valid_weather:
            for issue in weather_issues:
                self.logger.warning(f"Weather data validation issue: {issue}")
        
        # Validate outage records
        is_valid_outage, outage_issues = validate_outage_records(outage_records)
        if not is_valid_outage:
            for issue in outage_issues:
                self.logger.warning(f"Outage records validation issue: {issue}")
        
        # Check time range compatibility
        if 'timestamp' in weather_history.columns and 'start_time' in outage_records.columns:
            # Convert to datetime
            weather_times = pd.to_datetime(weather_history['timestamp'])
            outage_times = pd.to_datetime(outage_records['start_time'])
            
            # Get time ranges
            weather_range = (weather_times.min(), weather_times.max())
            outage_range = (outage_times.min(), outage_times.max())
            
            # Check if outage range is within weather range
            if outage_range[0] < weather_range[0] or outage_range[1] > weather_range[1]:
                self.logger.warning(
                    f"Outage time range ({outage_range[0]} to {outage_range[1]}) "
                    f"is not within weather time range ({weather_range[0]} to {weather_range[1]})"
                )
    
    def _identify_threat_thresholds(
        self,
        weather_history: pd.DataFrame,
        outage_records: pd.DataFrame
    ) -> Dict[str, Dict[str, Any]]:
        """
        Identify thresholds for environmental threats.
        
        Args:
            weather_history: DataFrame with weather data
            outage_records: DataFrame with outage records
            
        Returns:
            Dict: Dictionary with thresholds for each threat type
        """
        self.logger.info("Identifying environmental threat thresholds")
        
        thresholds = {}
        
        # Convert timestamps to datetime
        weather_history['timestamp'] = pd.to_datetime(weather_history['timestamp'])
        outage_records['start_time'] = pd.to_datetime(outage_records['start_time'])
        
        # Create outage flag time series
        outage_dates = pd.Series(
            1, 
            index=outage_records['start_time']
        ).resample('D').sum().fillna(0)
        
        # Align outage data with weather data
        aligned_data = pd.DataFrame({
            'timestamp': weather_history['timestamp']
        })
        aligned_data.set_index('timestamp', inplace=True)
        
        # Add outage flag
        aligned_data['outage_flag'] = 0
        aligned_data_daily = aligned_data.resample('D').first()
        aligned_data_daily.index = aligned_data_daily.index.date
        outage_dates.index = outage_dates.index.date
        
        for date in outage_dates.index:
            if date in aligned_data_daily.index:
                aligned_data_daily.loc[date, 'outage_flag'] = outage_dates.loc[date]
        
        # Convert back to original frequency
        for date in aligned_data.index.date:
            aligned_data.loc[aligned_data.index.date == date, 'outage_flag'] = \
                aligned_data_daily.loc[date, 'outage_flag'] if date in aligned_data_daily.index else 0
        
        # Analyze each threat type
        for threat_type in self.threat_types:
            variable = None
            direction = None
            
            # Determine variable and direction based on threat type
            if threat_type == 'high_temperature':
                variable = 'temperature'
                direction = 'high'
            elif threat_type == 'low_temperature':
                variable = 'temperature'
                direction = 'low'
            elif threat_type == 'high_wind':
                variable = 'wind_speed'
                direction = 'high'
            elif threat_type == 'precipitation':
                variable = 'precipitation'
                direction = 'high'
            else:
                self.logger.warning(f"Unsupported threat type: {threat_type}")
                continue
            
            # Check if variable exists in weather data
            if variable not in weather_history.columns:
                self.logger.warning(f"Variable '{variable}' not found in weather data")
                continue
            
            # Add weather variable to aligned data
            aligned_data[variable] = weather_history.set_index('timestamp')[variable]
            
            # Apply direction-specific transformation
            if direction == 'low':
                # For 'low' direction, invert values
                aligned_data[f'{variable}_transformed'] = -aligned_data[variable]
            else:
                # For 'high' direction, use values as-is
                aligned_data[f'{variable}_transformed'] = aligned_data[variable]
            
            # Find optimal threshold
            threshold_result = find_optimal_threshold(
                aligned_data[f'{variable}_transformed'],
                aligned_data['outage_flag']
            )
            
            # Get percentile-based threshold
            percentile = self.threshold_percentiles.get(threat_type, 95)
            if direction == 'low':
                percentile = 100 - percentile
            
            percentile_threshold = np.percentile(
                aligned_data[variable], 
                percentile
            )
            
            # Store thresholds
            if direction == 'low':
                # For 'low' direction, store raw value (not transformed)
                threshold_value = -threshold_result['threshold'] if threshold_result['threshold'] is not None else None
                thresholds[threat_type] = {
                    'variable': variable,
                    'direction': direction,
                    'optimal_threshold': threshold_value,
                    'percentile_threshold': percentile_threshold,
                    'percentile': percentile,
                    'avg_above': threshold_result['avg_below'],  # Inverted due to transformation
                    'avg_below': threshold_result['avg_above'],  # Inverted due to transformation
                    'ratio': 1/threshold_result['ratio'] if threshold_result['ratio'] else None,
                    'p_value': threshold_result['p_value']
                }
            else:
                thresholds[threat_type] = {
                    'variable': variable,
                    'direction': direction,
                    'optimal_threshold': threshold_result['threshold'],
                    'percentile_threshold': percentile_threshold,
                    'percentile': percentile,
                    'avg_above': threshold_result['avg_above'],
                    'avg_below': threshold_result['avg_below'],
                    'ratio': threshold_result['ratio'],
                    'p_value': threshold_result['p_value']
                }
        
        # Log threshold results
        for threat_type, result in thresholds.items():
            self.logger.info(
                f"{threat_type}: optimal threshold = {result['optimal_threshold']:.2f}, "
                f"percentile ({result['percentile']}) threshold = {result['percentile_threshold']:.2f}"
            )
            if result['p_value'] is not None:
                self.logger.info(
                    f"  p-value = {result['p_value']:.4f}, "
                    f"avg outages above/below = {result['avg_above']:.4f}/{result['avg_below']:.4f}, "
                    f"ratio = {result['ratio']:.2f}"
                )
        
        return thresholds
    
    def _calculate_threat_profiles(
        self,
        weather_history: pd.DataFrame
    ) -> Dict[str, pd.DataFrame]:
        """
        Calculate environmental threat profiles.
        
        Args:
            weather_history: DataFrame with weather data
            
        Returns:
            Dict: Dictionary with threat profiles for each threat type
        """
        self.logger.info("Calculating environmental threat profiles")
        
        threat_profiles = {}
        
        # Ensure timestamp is datetime
        weather_history['timestamp'] = pd.to_datetime(weather_history['timestamp'])
        
        # Calculate threat scores for each threat type
        for threat_type, threshold_info in self.weather_thresholds.items():
            variable = threshold_info['variable']
            direction = threshold_info['direction']
            
            # Use percentile threshold by default
            threshold = threshold_info['percentile_threshold']
            
            # Use optimal threshold if significant and available
            if (threshold_info['p_value'] is not None and 
                threshold_info['p_value'] < 0.05 and 
                threshold_info['optimal_threshold'] is not None):
                threshold = threshold_info['optimal_threshold']
            
            # Check if variable exists
            if variable not in weather_history.columns:
                self.logger.warning(f"Variable '{variable}' not found in weather data")
                continue
            
            # Create threat profile DataFrame
            profile_df = pd.DataFrame({
                'timestamp': weather_history['timestamp'],
                'value': weather_history[variable]
            })
            
            # Add location info if available
            if 'location' in weather_history.columns:
                profile_df['location'] = weather_history['location']
            elif 'station_id' in weather_history.columns:
                profile_df['location'] = weather_history['station_id']
            
            # Calculate threat level
            if direction == 'high':
                profile_df['exceeds_threshold'] = (profile_df['value'] > threshold).astype(int)
                profile_df['threat_level'] = np.maximum(
                    (profile_df['value'] - threshold) / (threshold * 0.5), 
                    0
                )
            else:  # 'low'
                profile_df['exceeds_threshold'] = (profile_df['value'] < threshold).astype(int)
                profile_df['threat_level'] = np.maximum(
                    (threshold - profile_df['value']) / (threshold * 0.5), 
                    0
                )
            
            # Cap threat level at 1.0
            profile_df['threat_level'] = np.minimum(profile_df['threat_level'], 1.0)
            
            # Calculate cumulative threat if configured
            if self.calculate_cumulative:
                # Create date column for resampling
                profile_df['date'] = profile_df['timestamp'].dt.date
                
                # Calculate daily maximum threat level
                daily_max = profile_df.groupby('date')['threat_level'].max().reset_index()
                daily_max.columns = ['date', 'daily_max_threat']
                
                # Calculate 7-day rolling sum of daily max threat
                daily_max['date'] = pd.to_datetime(daily_max['date'])
                daily_max = daily_max.sort_values('date')
                daily_max['cumulative_threat'] = daily_max['daily_max_threat'].rolling(7, min_periods=1).sum()
                
                # Map cumulative threat back to original dataframe
                date_to_cumulative = dict(zip(daily_max['date'].dt.date, daily_max['cumulative_threat']))
                profile_df['cumulative_threat'] = profile_df['date'].map(date_to_cumulative)
                
                # Normalize cumulative threat to 0-1 scale
                max_cumulative = profile_df['cumulative_threat'].max()
                if max_cumulative > 0:
                    profile_df['cumulative_threat_normalized'] = profile_df['cumulative_threat'] / max_cumulative
                else:
                    profile_df['cumulative_threat_normalized'] = 0
            
            # Add threat metadata
            profile_df['threat_type'] = threat_type
            profile_df['threshold'] = threshold
            
            # Store profile
            threat_profiles[threat_type] = profile_df
            
            self.logger.info(
                f"Calculated threat profile for {threat_type}: "
                f"{len(profile_df[profile_df['exceeds_threshold'] > 0])} threshold exceedances"
            )
        
        return threat_profiles
    
    def _analyze_lagged_correlations(
        self,
        weather_history: pd.DataFrame,
        outage_records: pd.DataFrame
    ) -> Dict[str, Dict[int, Tuple[float, float]]]:
        """
        Analyze time-lagged correlations between weather variables and outages.
        
        Args:
            weather_history: DataFrame with weather data
            outage_records: DataFrame with outage records
            
        Returns:
            Dict: Dictionary with lagged correlations for each variable
        """
        self.logger.info("Analyzing time-lagged correlations")
        
        lagged_correlations = {}
        
        # Convert timestamps to datetime
        weather_history['timestamp'] = pd.to_datetime(weather_history['timestamp'])
        outage_records['start_time'] = pd.to_datetime(outage_records['start_time'])
        
        # Create daily weather aggregates
        daily_weather = weather_history.copy()
        daily_weather['date'] = daily_weather['timestamp'].dt.date
        
        # Calculate daily statistics for each weather variable
        weather_variables = []
        for threat_type, threshold_info in self.weather_thresholds.items():
            variable = threshold_info['variable']
            if variable not in weather_variables:
                weather_variables.append(variable)
        
        daily_stats = {}
        for variable in weather_variables:
            if variable in daily_weather.columns:
                # Calculate daily max, min, and mean
                daily_max = daily_weather.groupby('date')[variable].max()
                daily_min = daily_weather.groupby('date')[variable].min()
                daily_mean = daily_weather.groupby('date')[variable].mean()
                
                daily_stats[f'{variable}_max'] = daily_max
                daily_stats[f'{variable}_min'] = daily_min
                daily_stats[f'{variable}_mean'] = daily_mean
        
        # Create daily outage counts
        daily_outages = outage_records.copy()
        daily_outages['date'] = daily_outages['start_time'].dt.date
        daily_outage_counts = daily_outages.groupby('date').size()
        
        # Create aligned dataframe with dates as index
        all_dates = sorted(set(list(daily_outage_counts.index) + 
                            [idx for stats in daily_stats.values() for idx in stats.index]))
        
        aligned_df = pd.DataFrame(index=all_dates)
        aligned_df['outage_count'] = daily_outage_counts
        aligned_df['outage_count'] = aligned_df['outage_count'].fillna(0)
        
        # Add weather statistics
        for stat_name, stat_series in daily_stats.items():
            aligned_df[stat_name] = stat_series
        
        # Fill NaN values
        aligned_df = aligned_df.fillna(method='ffill').fillna(method='bfill')
        
        # Calculate lagged correlations
        max_lag = self.max_lag_days
        
        for stat_name in daily_stats.keys():
            # Skip if column doesn't exist
            if stat_name not in aligned_df.columns:
                continue
                
            # Calculate time-lagged correlations
            lagged_results = calculate_time_lagged_correlation(
                aligned_df['outage_count'],
                aligned_df[stat_name],
                max_lag=max_lag,
                method='spearman'
            )
            
            lagged_correlations[stat_name] = lagged_results
            
            # Log strongest correlation
            strongest_lag = max(lagged_results.items(), key=lambda x: abs(x[1][0]))[0]
            strongest_corr = lagged_results[strongest_lag][0]
            strongest_p = lagged_results[strongest_lag][1]
            
            self.logger.info(
                f"{stat_name}: strongest correlation at lag {strongest_lag} days: "
                f"r = {strongest_corr:.4f}, p = {strongest_p:.4f}"
            )
        
        return lagged_correlations
    
    def _generate_visualizations(
        self,
        weather_history: pd.DataFrame,
        outage_records: pd.DataFrame,
        save_path: Optional[str] = None
    ):
        """
        Generate visualizations for environmental threat analysis.
        
        Args:
            weather_history: DataFrame with weather data
            outage_records: DataFrame with outage records
            save_path: Path to save visualizations
        """
        if save_path is None:
            return
            
        # Create directory if it doesn't exist
        viz_dir = os.path.join(save_path, 'visualizations')
        os.makedirs(viz_dir, exist_ok=True)
        
        # 1. Threat heatmaps for each threat type
        for threat_type, profile_df in self.threat_profiles.items():
            self.logger.info(f"Generating threat heatmap for {threat_type}")
            
            # Check if location information is available
            if 'location' in profile_df.columns:
                plot_environmental_threat_heatmap(
                    profile_df,
                    location_col='location',
                    threat_col='threat_level',
                    title=f'{threat_type.replace("_", " ").title()} Threat Heatmap',
                    save_path=os.path.join(viz_dir, f'{threat_type}_heatmap.png')
                )
        
        # 2. Time series with outage events
        for threat_type, profile_df in self.threat_profiles.items():
            self.logger.info(f"Generating time series plot for {threat_type}")
            
            # Prepare time series data
            time_series = profile_df.set_index('timestamp')['threat_level']
            
            # Plot time series with outages
            plot_time_series_with_events(
                time_series,
                outage_records,
                event_time_col='start_time',
                title=f'{threat_type.replace("_", " ").title()} Threat with Outage Events',
                save_path=os.path.join(viz_dir, f'{threat_type}_time_series.png')
            )
    
    def _save_results(self, save_path: str):
        """
        Save analysis results.
        
        Args:
            save_path: Path to save results
        """
        # Create directory if it doesn't exist
        os.makedirs(save_path, exist_ok=True)
        
        # Save threat profiles
        profiles_path = os.path.join(save_path, 'environmental_threat_profiles.pkl')
        with open(profiles_path, 'wb') as f:
            pickle.dump(self.threat_profiles, f)
        
        self.logger.info(f"Saved environmental threat profiles to {profiles_path}")
        
        # Save thresholds
        thresholds_path = os.path.join(save_path, 'environmental_thresholds.pkl')
        with open(thresholds_path, 'wb') as f:
            pickle.dump(self.weather_thresholds, f)
        
        thresholds_json_path = os.path.join(save_path, 'environmental_thresholds.json')
        import json
        with open(thresholds_json_path, 'w') as f:
            # Convert numpy values to standard Python types
            thresholds_json = {}
            for threat_type, threshold_info in self.weather_thresholds.items():
                thresholds_json[threat_type] = {
                    k: float(v) if isinstance(v, (np.float32, np.float64)) else v
                    for k, v in threshold_info.items() if v is not None
                }
            json.dump(thresholds_json, f, indent=2)
        
        self.logger.info(f"Saved environmental thresholds to {thresholds_path} and {thresholds_json_path}")
        
        # Save lagged correlations if available
        if self.lagged_correlations:
            correlations_path = os.path.join(save_path, 'lagged_correlations.pkl')
            with open(correlations_path, 'wb') as f:
                pickle.dump(self.lagged_correlations, f)
            
            self.logger.info(f"Saved lagged correlations to {correlations_path}")
    
    def load_threat_profiles(self, load_path: str) -> Dict[str, pd.DataFrame]:
        """
        Load previously calculated threat profiles.
        
        Args:
            load_path: Path to load profiles from
            
        Returns:
            Dict: Dictionary with threat profiles
        """
        # Determine file path
        profiles_path = os.path.join(load_path, 'environmental_threat_profiles.pkl')
        
        # Load threat profiles
        try:
            with open(profiles_path, 'rb') as f:
                self.threat_profiles = pickle.load(f)
            self.logger.info(f"Loaded environmental threat profiles from {profiles_path}")
        except Exception as e:
            self.logger.error(f"Error loading threat profiles: {e}")
            raise
        
        return self.threat_profiles
