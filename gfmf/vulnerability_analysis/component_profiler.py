"""
Component vulnerability profiling for the Grid Failure Modeling Framework.

This module analyzes and scores the vulnerability of power grid components
based on historical data and component characteristics.
"""

import os
import numpy as np
import pandas as pd
import pickle
import logging
from typing import Dict, List, Union, Optional, Any
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    confusion_matrix, roc_auc_score, roc_curve
)
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
import matplotlib.pyplot as plt

# Import utility functions
from .utils.statistical_tools import (
    calculate_time_lagged_correlation,
    estimate_failure_probability,
    bootstrap_confidence_interval
)
from .utils.visualization import (
    plot_component_vulnerability_scores,
    plot_vulnerability_distribution,
    plot_feature_importance
)
from .utils.validators import validate_grid_components, validate_outage_records

# Configure logging
logger = logging.getLogger(__name__)

class ComponentProfiler:
    """
    Component vulnerability profiling module.
    
    This class analyzes grid component vulnerability based on historical data
    and component characteristics.
    """
    
    def __init__(self, config: Dict[str, Any]):
        """
        Initialize component profiler.
        
        Args:
            config: Configuration dictionary
        """
        self.config = config
        self.logger = logging.getLogger(__name__)
        
        # Get component profiling config
        self.profiling_config = config.get('component_profiling', {})
        
        # Model configuration
        self.model_type = self.profiling_config.get('model_type', 'random_forest')
        self.test_size = self.profiling_config.get('test_size', 0.2)
        
        # Initialize attributes
        self.model = None
        self.feature_importance = None
        self.vulnerability_scores = None
        self.preprocessor = None
        
        self.logger.info("ComponentProfiler initialized")
    
    def analyze(
        self,
        grid_components: pd.DataFrame,
        outage_records: pd.DataFrame,
        save_path: Optional[str] = None
    ) -> pd.DataFrame:
        """
        Analyze component vulnerability based on historical data.
        
        Args:
            grid_components: DataFrame with grid component information
            outage_records: DataFrame with outage records
            save_path: Path to save results
            
        Returns:
            pd.DataFrame: Component vulnerability scores
        """
        self.logger.info("Starting component vulnerability analysis")
        
        # Validate input data
        self._validate_input_data(grid_components, outage_records)
        
        # Preprocess data for vulnerability analysis
        preprocessed_data = self._preprocess_data(grid_components, outage_records)
        
        # Build and train vulnerability model
        self._build_vulnerability_model(preprocessed_data)
        
        # Calculate vulnerability scores
        self.vulnerability_scores = self._calculate_vulnerability_scores(
            grid_components, 
            preprocessed_data['failure_rates']
        )
        
        # Generate visualization
        self._generate_visualizations(save_path)
        
        # Save results if path provided
        if save_path:
            os.makedirs(save_path, exist_ok=True)
            self._save_results(save_path)
        
        self.logger.info(f"Completed component vulnerability analysis for {len(self.vulnerability_scores)} components")
        
        return self.vulnerability_scores
    
    def _validate_input_data(
        self,
        grid_components: pd.DataFrame,
        outage_records: pd.DataFrame
    ):
        """
        Validate input data for component profiling.
        
        Args:
            grid_components: DataFrame with grid component information
            outage_records: DataFrame with outage records
        """
        # Validate grid components
        is_valid_grid, grid_issues = validate_grid_components(grid_components)
        if not is_valid_grid:
            for issue in grid_issues:
                self.logger.warning(f"Grid components validation issue: {issue}")
        
        # Validate outage records
        is_valid_outage, outage_issues = validate_outage_records(outage_records)
        if not is_valid_outage:
            for issue in outage_issues:
                self.logger.warning(f"Outage records validation issue: {issue}")
        
        # Check compatibility
        grid_component_ids = set(grid_components['component_id'])
        outage_component_ids = set(outage_records['component_id'])
        
        # Check for outages for non-existent components
        invalid_outage_ids = outage_component_ids - grid_component_ids
        if invalid_outage_ids:
            self.logger.warning(f"Found {len(invalid_outage_ids)} outage records for non-existent components")
    
    def _preprocess_data(
        self,
        grid_components: pd.DataFrame,
        outage_records: pd.DataFrame
    ) -> Dict[str, Any]:
        """
        Preprocess data for vulnerability analysis.
        
        Args:
            grid_components: DataFrame with grid component information
            outage_records: DataFrame with outage records
            
        Returns:
            Dict: Dictionary with preprocessed data
        """
        self.logger.info("Preprocessing data for vulnerability analysis")
        
        # Calculate failure rates
        time_window = 365  # Default to 1 year
        if 'end_time' in outage_records.columns and 'start_time' in outage_records.columns:
            # Calculate time window from outage data
            start_times = pd.to_datetime(outage_records['start_time'])
            end_times = pd.to_datetime(outage_records['end_time'])
            time_window = (end_times.max() - start_times.min()).days
        
        # Calculate failure rates (failures per day)
        failure_rates = estimate_failure_probability(
            grid_components,
            outage_records,
            time_window=max(time_window, 1),  # Ensure positive time window
            component_id_col='component_id'
        )
        
        # Calculate average outage duration
        outage_durations = {}
        if all(col in outage_records.columns for col in ['component_id', 'start_time', 'end_time']):
            # Convert to datetime if needed
            outage_records['start_time'] = pd.to_datetime(outage_records['start_time'])
            outage_records['end_time'] = pd.to_datetime(outage_records['end_time'])
            
            # Calculate duration in hours
            outage_records['duration_hours'] = (
                outage_records['end_time'] - outage_records['start_time']
            ).dt.total_seconds() / 3600
            
            # Calculate average duration per component
            for component_id, group in outage_records.groupby('component_id'):
                outage_durations[component_id] = group['duration_hours'].mean()
        
        # Add more outage metrics as needed...
        
        # Create feature matrix for modeling
        features_df = self._create_feature_matrix(grid_components, failure_rates, outage_durations)
        
        # Define target variable based on failure rate threshold
        # Components with failure rate > 75th percentile are considered "vulnerable"
        threshold = failure_rates.quantile(0.75)
        target = (failure_rates > threshold).astype(int)
        
        # Combine features and target
        combined_df = features_df.copy()
        combined_df['target'] = target
        
        return {
            'features': features_df,
            'target': target,
            'failure_rates': failure_rates,
            'outage_durations': outage_durations,
            'combined': combined_df
        }
    
    def _create_feature_matrix(
        self,
        grid_components: pd.DataFrame,
        failure_rates: pd.Series,
        outage_durations: Dict[str, float]
    ) -> pd.DataFrame:
        """
        Create feature matrix for vulnerability modeling.
        
        Args:
            grid_components: DataFrame with grid component information
            failure_rates: Series with failure rates per component
            outage_durations: Dictionary with average outage duration per component
            
        Returns:
            pd.DataFrame: Feature matrix
        """
        # Start with grid components data
        features_df = grid_components.copy()
        
        # Add outage duration as feature
        features_df['avg_outage_duration'] = features_df['component_id'].map(outage_durations)
        
        # Fill missing values
        features_df['avg_outage_duration'] = features_df['avg_outage_duration'].fillna(0)
        
        # Add derived features
        
        # 1. Component age (if available)
        if 'installation_date' in features_df.columns:
            features_df['installation_date'] = pd.to_datetime(features_df['installation_date'])
            features_df['age_years'] = (
                pd.Timestamp.now() - features_df['installation_date']
            ).dt.days / 365.25
        
        # 2. Component capacity/rating (if available)
        for rating_col in ['capacity_mw', 'rating_kv', 'rating_mva']:
            if rating_col in features_df.columns:
                # Create buckets for ratings
                features_df[f'{rating_col}_bucket'] = pd.qcut(
                    features_df[rating_col],
                    q=5,
                    labels=['very_low', 'low', 'medium', 'high', 'very_high'],
                    duplicates='drop'
                )
        
        # 3. Location-based features (if available)
        if all(col in features_df.columns for col in ['latitude', 'longitude']):
            # Coastal proximity (simplified example)
            # This would normally use a more complex algorithm or lookup
            features_df['is_coastal'] = (
                (features_df['longitude'] > -125) & 
                (features_df['longitude'] < -65) &
                (
                    (features_df['latitude'] > 25) & 
                    (features_df['latitude'] < 49) | 
                    (features_df['latitude'] > 49) & 
                    (features_df['latitude'] < 60) & 
                    (features_df['longitude'] > -125) & 
                    (features_df['longitude'] < -115)
                )
            )
        
        # 4. Component type features
        if 'component_type' in features_df.columns:
            # For non-categorical models, create dummy variables
            for component_type in features_df['component_type'].unique():
                features_df[f'is_{component_type}'] = (
                    features_df['component_type'] == component_type
                ).astype(int)
        
        # 5. Connectivity features (if available)
        if 'connected_components' in features_df.columns:
            features_df['connection_count'] = features_df['connected_components'].str.len()
        
        # 6. Maintenance features (if available)
        if 'last_maintenance_date' in features_df.columns:
            features_df['last_maintenance_date'] = pd.to_datetime(features_df['last_maintenance_date'])
            features_df['days_since_maintenance'] = (
                pd.Timestamp.now() - features_df['last_maintenance_date']
            ).dt.days
        
        # Drop columns not useful for modeling
        columns_to_drop = [
            'component_id',  # Identifier, not a feature
            'installation_date',  # Already used to calculate age
            'last_maintenance_date',  # Already used to calculate days_since_maintenance
            'connected_components'  # Already used to calculate connection_count
        ]
        
        # Only drop columns that exist
        columns_to_drop = [col for col in columns_to_drop if col in features_df.columns]
        features_df = features_df.drop(columns=columns_to_drop)
        
        return features_df
    
    def _build_vulnerability_model(self, preprocessed_data: Dict[str, Any]):
        """
        Build and train vulnerability prediction model.
        
        Args:
            preprocessed_data: Dictionary with preprocessed data
        """
        self.logger.info(f"Building vulnerability model using {self.model_type}")
        
        # Get features and target
        features = preprocessed_data['features']
        target = preprocessed_data['target']
        
        # Identify categorical and numeric columns
        categorical_cols = features.select_dtypes(include=['object', 'category']).columns.tolist()
        numeric_cols = features.select_dtypes(include=['int64', 'float64']).columns.tolist()
        
        # Handle missing values separately for numeric and categorical columns
        # For numeric columns, fill with mean
        if numeric_cols:
            features[numeric_cols] = features[numeric_cols].fillna(features[numeric_cols].mean())
            # If there are still NaNs (e.g., in columns that were all NaN), replace with 0
            features[numeric_cols] = features[numeric_cols].fillna(0)
        
        # For categorical columns, fill with most frequent value or a placeholder
        if categorical_cols:
            for col in categorical_cols:
                if features[col].isna().any():
                    # Get the most frequent value
                    most_frequent = features[col].mode().iloc[0] if not features[col].mode().empty else 'unknown'
                    features[col] = features[col].fillna(most_frequent)
        
        # Create preprocessing pipeline
        preprocessor = ColumnTransformer(
            transformers=[
                ('num', StandardScaler(), numeric_cols),
                ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)
            ],
            remainder='drop'  # Drop columns not specified
        )
        
        # Create model
        if self.model_type == 'random_forest':
            model = RandomForestClassifier(
                n_estimators=100,
                max_depth=None,
                min_samples_split=2,
                min_samples_leaf=1,
                random_state=42
            )
        elif self.model_type == 'gradient_boosting':
            model = GradientBoostingClassifier(
                n_estimators=100,
                learning_rate=0.1,
                max_depth=3,
                random_state=42
            )
        else:
            raise ValueError(f"Unsupported model type: {self.model_type}")
        
        # Create pipeline
        self.pipeline = Pipeline([
            ('preprocessor', preprocessor),
            ('model', model)
        ])
        
        # Split data
        X_train, X_test, y_train, y_test = train_test_split(
            features, target, test_size=self.test_size, random_state=42
        )
        
        # Train model
        self.pipeline.fit(X_train, y_train)
        
        # Evaluate model
        y_pred = self.pipeline.predict(X_test)
        y_prob = self.pipeline.predict_proba(X_test)[:, 1]
        
        # Calculate metrics
        accuracy = accuracy_score(y_test, y_pred)
        precision = precision_score(y_test, y_pred, zero_division=0)
        recall = recall_score(y_test, y_pred, zero_division=0)
        f1 = f1_score(y_test, y_pred, zero_division=0)
        
        # Calculate ROC AUC if possible
        if len(np.unique(y_test)) > 1:
            roc_auc = roc_auc_score(y_test, y_prob)
        else:
            roc_auc = float('nan')
        
        # Log metrics
        self.logger.info(f"Model evaluation metrics:")
        self.logger.info(f"  Accuracy: {accuracy:.4f}")
        self.logger.info(f"  Precision: {precision:.4f}")
        self.logger.info(f"  Recall: {recall:.4f}")
        self.logger.info(f"  F1 Score: {f1:.4f}")
        self.logger.info(f"  ROC AUC: {roc_auc:.4f}")
        
        # Extract feature importance
        model_step = self.pipeline.named_steps['model']
        if hasattr(model_step, 'feature_importances_'):
            # Get feature names after preprocessing
            preprocessor_step = self.pipeline.named_steps['preprocessor']
            if hasattr(preprocessor_step, 'get_feature_names_out'):
                # For scikit-learn >= 1.0
                feature_names = preprocessor_step.get_feature_names_out()
            else:
                # For older scikit-learn versions
                feature_names = []
                for name, _, cols in preprocessor_step.transformers_:
                    if name == 'num':
                        feature_names.extend(cols)
                    elif name == 'cat':
                        for col in cols:
                            for cat in features[col].unique():
                                feature_names.append(f"{col}_{cat}")
            
            # Create feature importance series
            self.feature_importance = pd.Series(
                model_step.feature_importances_,
                index=feature_names
            ).sort_values(ascending=False)
        
        self.logger.info(f"Vulnerability model built successfully")
    
    def _calculate_vulnerability_scores(
        self,
        grid_components: pd.DataFrame,
        failure_rates: pd.Series
    ) -> pd.DataFrame:
        """
        Calculate vulnerability scores for grid components.
        
        Args:
            grid_components: DataFrame with grid component information
            failure_rates: Series with failure rates per component
            
        Returns:
            pd.DataFrame: DataFrame with vulnerability scores
        """
        self.logger.info("Calculating vulnerability scores")
        
        # Create DataFrame with component IDs
        scores_df = pd.DataFrame({
            'component_id': grid_components['component_id'],
            'failure_rate': failure_rates
        })
        
        # Add component type if available
        if 'component_type' in grid_components.columns:
            scores_df['component_type'] = grid_components.set_index('component_id')['component_type']
        
        # Calculate raw vulnerability score as failure probability
        scores_df['raw_score'] = scores_df['failure_rate']
        
        # Normalize to 0-1 scale
        if not scores_df['raw_score'].empty and scores_df['raw_score'].max() > 0:
            scores_df['vulnerability_score'] = scores_df['raw_score'] / scores_df['raw_score'].max()
        else:
            scores_df['vulnerability_score'] = 0
        
        # Use model predictions as another factor (if model was built)
        if hasattr(self, 'pipeline') and self.pipeline is not None:
            # Prepare data for prediction
            X_pred = grid_components.set_index('component_id')
            
            # Add columns needed for prediction if they're missing
            features = self.pipeline.named_steps['preprocessor'].transformers_
            for _, _, cols in features:
                for col in cols:
                    if col not in X_pred.columns:
                        X_pred[col] = 0  # Default value
            
            # Make prediction
            try:
                model_scores = self.pipeline.predict_proba(X_pred)[:, 1]
                scores_df['model_score'] = model_scores
                
                # Combine model score with failure rate (weighted average)
                scores_df['vulnerability_score'] = 0.7 * scores_df['vulnerability_score'] + 0.3 * scores_df['model_score']
            except Exception as e:
                self.logger.warning(f"Error making model predictions: {e}")
                self.logger.warning("Using only failure rates for vulnerability scores")
        
        # Add confidence intervals if enough data
        try:
            component_ids = scores_df['component_id'].values
            lower_bounds = []
            upper_bounds = []
            
            for comp_id in component_ids:
                try:
                    # Get outage data for this component - simplified approach for demonstration
                    raw_score = scores_df.loc[scores_df['component_id'] == comp_id, 'raw_score'].values[0]
                    # Only generate samples if raw_score is valid (non-zero, not NaN)
                    if np.isfinite(raw_score) and raw_score > 0:
                        samples = [raw_score] * 100
                        samples = np.random.normal(raw_score, raw_score * 0.1, 100)
                        
                        # Calculate confidence interval
                        lower, upper = bootstrap_confidence_interval(
                            pd.Series(samples),
                            confidence=0.95
                        )
                    else:
                        # If raw_score is invalid, use default confidence interval
                        lower = 0
                        upper = 0.1
                except Exception as inner_e:
                    self.logger.warning(f"Error calculating CI for component {comp_id}: {inner_e}")
                    # Use default values for this component
                    lower = 0
                    upper = 0.1
                    
                lower_bounds.append(lower)
                upper_bounds.append(upper)
            
            scores_df['lower_bound'] = lower_bounds
            scores_df['upper_bound'] = upper_bounds
        except Exception as e:
            self.logger.warning(f"Error calculating confidence intervals: {e}")
            # Set default confidence bounds as fallback
            scores_df['lower_bound'] = scores_df['vulnerability_score'] * 0.9
            scores_df['upper_bound'] = scores_df['vulnerability_score'] * 1.1
        
        # Add risk categorization
        scores_df['risk_category'] = pd.cut(
            scores_df['vulnerability_score'],
            bins=[0, 0.2, 0.4, 0.6, 0.8, 1.0],
            labels=['very_low', 'low', 'medium', 'high', 'very_high'],
            include_lowest=True
        )
        
        return scores_df
    
    def _generate_visualizations(self, save_path: Optional[str] = None):
        """
        Generate visualizations for vulnerability analysis.
        
        Args:
            save_path: Path to save visualizations
        """
        if save_path is None:
            return
            
        # Create directory if it doesn't exist
        viz_dir = os.path.join(save_path, 'visualizations')
        os.makedirs(viz_dir, exist_ok=True)
        
        # 1. Component vulnerability scores
        self.logger.info("Generating component vulnerability scores visualization")
        plot_component_vulnerability_scores(
            self.vulnerability_scores,
            top_n=20,
            save_path=os.path.join(viz_dir, 'top_vulnerable_components.png')
        )
        
        # 2. Vulnerability distribution by component type
        if 'component_type' in self.vulnerability_scores.columns:
            self.logger.info("Generating vulnerability distribution visualization")
            plot_vulnerability_distribution(
                self.vulnerability_scores,
                group_by='component_type',
                save_path=os.path.join(viz_dir, 'vulnerability_distribution.png')
            )
        
        # 3. Feature importance
        if hasattr(self, 'feature_importance') and self.feature_importance is not None:
            self.logger.info("Generating feature importance visualization")
            plot_feature_importance(
                self.feature_importance,
                save_path=os.path.join(viz_dir, 'feature_importance.png')
            )
    
    def _save_results(self, save_path: str):
        """
        Save analysis results.
        
        Args:
            save_path: Path to save results
        """
        # Create directory if it doesn't exist
        os.makedirs(save_path, exist_ok=True)
        
        # Save vulnerability scores
        scores_path = os.path.join(save_path, 'component_vulnerability_scores.pkl')
        with open(scores_path, 'wb') as f:
            pickle.dump(self.vulnerability_scores, f)
        
        scores_csv_path = os.path.join(save_path, 'component_vulnerability_scores.csv')
        self.vulnerability_scores.to_csv(scores_csv_path, index=False)
        
        self.logger.info(f"Saved vulnerability scores to {scores_path} and {scores_csv_path}")
        
        # Save model if available
        if hasattr(self, 'pipeline') and self.pipeline is not None:
            model_path = os.path.join(save_path, 'vulnerability_model.pkl')
            with open(model_path, 'wb') as f:
                pickle.dump(self.pipeline, f)
            self.logger.info(f"Saved vulnerability model to {model_path}")
        
        # Save feature importance if available
        if hasattr(self, 'feature_importance') and self.feature_importance is not None:
            importance_path = os.path.join(save_path, 'feature_importance.pkl')
            with open(importance_path, 'wb') as f:
                pickle.dump(self.feature_importance, f)
            
            importance_csv_path = os.path.join(save_path, 'feature_importance.csv')
            self.feature_importance.to_csv(importance_csv_path, header=['importance'])
            
            self.logger.info(f"Saved feature importance to {importance_path} and {importance_csv_path}")
    
    def load_vulnerability_scores(self, load_path: str) -> pd.DataFrame:
        """
        Load previously calculated vulnerability scores.
        
        Args:
            load_path: Path to load scores from
            
        Returns:
            pd.DataFrame: Vulnerability scores
        """
        # Determine file path
        scores_path = os.path.join(load_path, 'component_vulnerability_scores.pkl')
        
        # Load vulnerability scores
        try:
            with open(scores_path, 'rb') as f:
                self.vulnerability_scores = pickle.load(f)
            self.logger.info(f"Loaded vulnerability scores from {scores_path}")
        except Exception as e:
            self.logger.error(f"Error loading vulnerability scores: {e}")
            raise
        
        return self.vulnerability_scores
